{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#required packages\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from scipy import signal, stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "#my funcs\n",
    "from ecog_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outlier rejection function\n",
    "def reject_outliers(data, thr = 1.5, twosided = True):\n",
    "    clean = []\n",
    "    q1 = np.quantile(data, 0.25)\n",
    "    q3 = np.quantile(data, 0.75)\n",
    "    iqr = q3-q1\n",
    "    outlier_n = 0\n",
    "    for point in data:\n",
    "        if twosided:\n",
    "            if point <= q3 + thr*iqr and point >= q1 - thr*iqr:\n",
    "                clean.append(point)\n",
    "            else:\n",
    "                outlier_n +=1\n",
    "        else:\n",
    "            if point <= q3 + thr*iqr:\n",
    "                clean.append(point)\n",
    "            else:\n",
    "                outlier_n += 1\n",
    "    if outlier_n >0:\n",
    "        print(f'found {outlier_n} outliers')\n",
    "    \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random funcs\n",
    "def q1(x):\n",
    "    return x.quantile(0.25)\n",
    "\n",
    "def q3(x):\n",
    "    return x.quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SUFFIX = 'spectral_final'\n",
    "DATA_DIR = 'C:/Users/marty/Projects/sleep_new/res_temp/*.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = glob.glob(DATA_DIR)\n",
    "STATE_PATHS = [PATH for PATH in DIR if DATA_SUFFIX in PATH and 'state' in PATH]\n",
    "TIME_PATHS = [PATH for PATH in DIR if DATA_SUFFIX in PATH and 'time' in PATH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6810/6810 [00:02<00:00, 3301.73it/s]\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "state_data = []\n",
    "for path in tqdm(STATE_PATHS):\n",
    "    state_data.append(pickle.load(open(path, 'rb')))\n",
    "state_data = pd.concat(state_data).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6810/6810 [00:00<00:00, 7135.89it/s]\n"
     ]
    }
   ],
   "source": [
    "time_data = []\n",
    "for path in tqdm(TIME_PATHS):\n",
    "    time_data.append(pickle.load(open(path, 'rb')))\n",
    "time_data = pd.concat(time_data).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_data['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time_data['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#things to set groups/injs\n",
    "#assign groups - if rat is not here, then in  sal\n",
    "w_cbn_ids = [5,7,7,12,14,16] \n",
    "w_sal_ids = [6,8,10,11,13,15]\n",
    "cbn_ids = [23,24,31,35,42,46,52]\n",
    "veh_ids = [21,26,33,34,43,45,55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mark days where single injections occured, format YYYY-MM-DD (same as index col)\n",
    "single_inj_dates=pd.to_datetime(['2023-11-18 08:30','2024-01-03 08:30','2023-04-05 08:30','2023-06-07 08:30', '2024-03-04 08:30', '2024-03-21'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set cont inj\n",
    "cont_inj_day1 = pd.to_datetime(['2023-04-09 08:30','2023-05-29 08:30','2023-11-08 08:30','2024-01-08 08:30','2024-02-24 08:30','2024-03-24 08:30'])\n",
    "cont_inj_day2 = pd.to_datetime(['2023-04-10 08:30','2023-05-30 08:30','2023-11-09 08:30','2024-01-09 08:30','2024-02-25 08:30','2024-03-25 08:30'])\n",
    "cont_inj_day3 = pd.to_datetime(['2023-04-11 08:30','2023-05-31 08:30','2023-11-10 08:30','2024-01-10 08:30','2024-02-26 08:30','2024-03-26 08:30'])\n",
    "cont_inj_day4 = pd.to_datetime(['2023-04-12 08:30','2023-06-01 08:30','2023-11-11 08:30','2024-01-11 08:30','2024-02-27 08:30','2024-03-27 08:30'])\n",
    "cont_inj_day5 = pd.to_datetime(['2023-04-13 08:30','2023-06-02 08:30','2023-11-12 08:30','2024-01-12 08:30','2024-02-28 08:30','2024-03-28 08:30'])\n",
    "cont_inj_day6 = pd.to_datetime(['2023-11-13 08:30','2024-01-13 08:30','2024-02-29 08:30','2024-03-29 08:30'])\n",
    "cont_inj_day7 = pd.to_datetime(['2023-11-14 08:30','2024-01-14 08:30','2024-03-01 08:30'])\n",
    "\n",
    "cont_inj_dates = [cont_inj_day1,cont_inj_day2,cont_inj_day3,cont_inj_day4,cont_inj_day5,cont_inj_day6,cont_inj_day7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up a cat dtype for injs\n",
    "from pandas import CategoricalDtype\n",
    "inj_list = ['none','single', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5','cont6', 'cont7', 'sp_sp', 'sp_w']\n",
    "inj_cat_type = CategoricalDtype(categories=inj_list,ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set spirulina injs the same way\n",
    "sp_sp = [11,13,15,21,24,26,32,34,41,43,45]\n",
    "sp_w = [12,14,23,25,31,33,35,42,44,46]\n",
    "sp_dates = pd.to_datetime(['2023-06-22 08:30','2023-06-23 08:30','2023-06-24 08:30','2023-06-25 08:30','2023-06-26 08:30','2023-06-27 08:30',\n",
    "                           '2023-11-30 08:30','2023-12-01 08:30','2023-12-02 08:30','2023-12-03 08:30','2023-12-04 08:30',\n",
    "                           '2024-01-20 08:30','2024-01-21 08:30','2024-01-22 08:30','2024-01-23 08:30','2024-01-24 08:30','2024-01-25 08:30',\n",
    "                           '2024-03-10 08:30','2024-03-11 08:30','2024-03-12 08:30','2024-03-13 08:30','2024-03-14 08:30','2024-03-15 08:30'                                                    \n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set groups for state data\n",
    "state_data['group'] = 'sal'\n",
    "state_data['group'].loc[state_data['id'].isin(w_cbn_ids)] = 'w_cbn'\n",
    "state_data['group'].loc[state_data['id'].isin(w_sal_ids)] = 'w_sal'\n",
    "state_data['group'].loc[state_data['id'].isin(cbn_ids)] = 'cbn'\n",
    "state_data['group'].loc[state_data['id'].isin(veh_ids)] = 'veh'\n",
    "#set injection dates\n",
    "state_data['inj']='none'\n",
    "\n",
    "#mark single injs\n",
    "for date in single_inj_dates:\n",
    "    state_data['inj'][(state_data['time']>=date)&(state_data['time']<date+pd.DateOffset(hours=24))]='single'\n",
    "#mark cont injs\n",
    "for i, day in enumerate(cont_inj_dates):\n",
    "    for date in day:\n",
    "        state_data['inj'][(state_data['time']>=date)&(state_data['time']<date+pd.DateOffset(hours=24))]=f'cont{i+1}'\n",
    "#mark spirulina experiment dates\n",
    "for date in sp_dates:\n",
    "    state_data['inj'].loc[((state_data['time']>=date)&(state_data['time']<date+pd.DateOffset(hours=24)))&(state_data['id'].isin(sp_sp))] = 'sp_sp'\n",
    "    state_data['inj'].loc[((state_data['time']>=date)&(state_data['time']<date+pd.DateOffset(hours=24)))&(state_data['id'].isin(sp_w))] = 'sp_w'\n",
    "    \n",
    "#convert to categorical dtype\n",
    "state_data['inj'] = state_data['inj'].astype(inj_cat_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data['inj'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set groups for time data\n",
    "time_data['group'] = 'sal'\n",
    "time_data['group'].loc[time_data['id'].isin(w_cbn_ids)] = 'w_cbn'\n",
    "time_data['group'].loc[time_data['id'].isin(w_sal_ids)] = 'w_sal'\n",
    "time_data['group'].loc[time_data['id'].isin(cbn_ids)] = 'cbn'\n",
    "time_data['group'].loc[time_data['id'].isin(veh_ids)] = 'veh'\n",
    "#set injection dates\n",
    "time_data['inj']='none'\n",
    "\n",
    "#mark single injs\n",
    "for date in single_inj_dates:\n",
    "    time_data['inj'][(time_data['time']>=date)&(time_data['time']<date+pd.DateOffset(hours=24))]='single'\n",
    "#mark cont injs\n",
    "for i, day in enumerate(cont_inj_dates):\n",
    "    for date in day:\n",
    "        time_data['inj'][(time_data['time']>=date)&(time_data['time']<date+pd.DateOffset(hours=24))]=f'cont{i+1}'\n",
    "#mark spirulina experiment dates\n",
    "for date in sp_dates:\n",
    "    time_data['inj'].loc[((time_data['time']>=date)&(time_data['time']<date+pd.DateOffset(hours=24)))&(time_data['id'].isin(sp_sp))] = 'sp_sp'\n",
    "    time_data['inj'].loc[((time_data['time']>=date)&(time_data['time']<date+pd.DateOffset(hours=24)))&(time_data['id'].isin(sp_w))] = 'sp_w'\n",
    "    \n",
    "#convert to categorical dtype\n",
    "time_data['inj'] = time_data['inj'].astype(inj_cat_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data['inj'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for now, select only tween experiment\n",
    "#also discard where no injs happened\n",
    "w_exp = ['w_sal','w_cbn']\n",
    "sp_exp = ['sp_sp','sp_w']\n",
    "no_injs = ['none']\n",
    "time_data = time_data[~time_data['group'].isin(w_exp)&~(time_data['inj'].isin(sp_exp))]\n",
    "time_data = time_data[time_data['inj']!='none']\n",
    "state_data = state_data[~state_data['group'].isin(w_exp)&~(state_data['inj'].isin(sp_exp))]\n",
    "state_data = state_data[state_data['inj']!='none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all data is loaded!\n",
    "#let's check time data first\n",
    "time_data['group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix categories\n",
    "time_data[['maxpow', 'meanpow', 'maxpowf', 'meanpowf']] = time_data[['maxpow', 'meanpow', 'maxpowf', 'meanpowf']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nans if there are any\n",
    "time_data = time_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see if this works - need to do also by channel\n",
    "#freq to resample to\n",
    "freq = '30min'\n",
    "#if freq = 60 min change start to 08:00 and end to 07:59, if = 30 or below keep 08:30 and 08:29\n",
    "time_list = pd.date_range(start = '08:30:00', end = '23:59:59', freq = freq).strftime('%H:%M').tolist()\n",
    "time_list.extend(pd.date_range(start = '00:00:00', end = '08:29:59', freq = freq).strftime('%H:%M').tolist())\n",
    "#create an ordered categorical index\n",
    "from pandas.api.types import CategoricalDtype\n",
    "cat_type = CategoricalDtype(categories=time_list,ordered=True)\n",
    "#resampling\n",
    "resampled = []\n",
    "for id in time_data['id'].unique():\n",
    "    for ch in time_data['channel'].unique():\n",
    "        id_subset = time_data.loc[(time_data['id']==id)&(time_data['channel']==ch)]\n",
    "        id_subset = id_subset.dropna()\n",
    "        numeric = id_subset.loc[:,id_subset.dtypes == float]\n",
    "        numeric['time'] = id_subset['time']\n",
    "        numeric = numeric.resample(freq, on = 'time').mean()\n",
    "        nonnumeric = id_subset.loc[:,id_subset.dtypes != float]\n",
    "        nonnumeric = nonnumeric.resample(freq, on = 'time').first()\n",
    "        resampled.append(nonnumeric.join(numeric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data = pd.concat(resampled)\n",
    "time_data['hour'] = time_data.index.strftime('%H:%M').astype(cat_type)\n",
    "#drop nans if there are any\n",
    "time_data = time_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chs = time_data['channel'].unique()\n",
    "chs = ['lfp']\n",
    "injs = time_data['inj'].unique()\n",
    "params = ['maxpow', 'meanpow', 'maxpowf', 'meanpowf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming dicts\n",
    "ch_renaming_dict = {'l_ecog':'ECoG, L', 'r_ecog':'ECoG, R', 'lfp':'NAcc, LFP', 'emg':'EMG'}\n",
    "param_renaming_dict = {'maxpow':'Peak PSD, mV$^2$/Hz', 'meanpow': 'Average PSD, mV$^2$/Hz', 'maxpowf':'Peak frequency, Hz', 'meanpowf':'Average PSD frequency, Hz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will not split by day\n",
    "# #temp - only plot lfp\n",
    "# for inj in injs:\n",
    "#     for ch in chs:\n",
    "#         fig, ax = plt.subplots(4,1,figsize = (10,10))\n",
    "#         for i, param in enumerate(params):\n",
    "#             sns.lineplot(data = time_data.loc[(time_data['channel'] == ch)&(time_data['inj'] == inj)], x = 'hour', y = param, hue = 'group', ax = ax[i], estimator = 'median', errorbar = 'ci')\n",
    "#             # ax[i].set(ylim = (0,time_data.loc[(time_data['channel'] == ch)&(time_data['inj'] == inj), param].quantile(0.75)))\n",
    "#             ax[i].tick_params(axis = 'x', labelrotation=90)\n",
    "#             # for index, label in enumerate(ax[i].xaxis.get_ticklabels()):\n",
    "#             #     if index % 6 != 0:\n",
    "#             #         label.set_visible(False)\n",
    "#         fig.suptitle(str(ch)+'_'+str(inj))\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #by day light dark\n",
    "# time_data['phase'] = 'dark'\n",
    "# time_data.loc[(time_data['hour'] >= '08:30')&(time_data['hour'] < '20:30'), 'phase'] = 'light'\n",
    "# byphase_full = time_data.groupby(['id','channel','group','inj','phase']).median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #no point\n",
    "# for ch in chs:\n",
    "#     fig, ax = plt.subplots(len(byphase_full['inj'].unique()), 4, figsize = (10,20))\n",
    "#     for i_row, inj in enumerate(byphase_full['inj'].unique()):\n",
    "#         for i_col, param in enumerate(params):\n",
    "#             sns.boxplot(data = byphase_full.loc[byphase_full['inj'] == inj], x = 'phase', hue = 'group', y = param, ax = ax[i_row][i_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should check medians instead\n",
    "time_medians = time_data.groupby(['id','channel','group','hour']).median(numeric_only=True).reset_index().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how much data is available in total?\n",
    "n_cbn = len(time_medians[time_medians['group']=='cbn']['id'].unique())\n",
    "n_veh = len(time_medians[time_medians['group']=='veh']['id'].unique())\n",
    "n_sal = len(time_medians[time_medians['group']=='sal']['id'].unique())\n",
    "print(f'cbn group n = {n_cbn}')\n",
    "print(f'veh group n = {n_veh}')\n",
    "print(f'sal group n = {n_sal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STATS\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "#also add significant hours to param list\n",
    "signif_params = []\n",
    "\n",
    "f = open('results/spectral_tween_medians_byhour_stats.txt','w')\n",
    "for i, param in enumerate(params):\n",
    "    \n",
    "    signif_times = []\n",
    "    for ch in chs:\n",
    "        \n",
    "        for time in time_medians['hour'].unique():\n",
    "            time_subset = time_medians.loc[(time_medians['hour']==time)&(time_medians['channel']==ch)]\n",
    "            cbn = time_subset[time_subset['group'] == 'cbn'][param].tolist()\n",
    "            veh = time_subset[time_subset['group'] == 'veh'][param].tolist()\n",
    "            sal = time_subset[time_subset['group'] == 'sal'][param].tolist()\n",
    "            \n",
    "            #remove outliers with 1.5*IQR\n",
    "            cbn = reject_outliers(cbn)\n",
    "            veh = reject_outliers(veh)\n",
    "            sal = reject_outliers(sal)\n",
    "                    \n",
    "            if cbn and veh and sal:\n",
    "                if (np.sum(cbn) != np.sum(veh)) and (np.sum(cbn)!=np.sum(sal)):\n",
    "                    stat, p = stats.kruskal(cbn, veh, sal)\n",
    "                    if p < 0.05:\n",
    "                        print(f'n cbn: {len(cbn)}, n veh: {len(veh)}, n sal: {len(sal)}')\n",
    "                        print(f'hour {time} param {param} significant, p = {p}, stat = {stat}')\n",
    "                        f.write(f'n cbn: {len(cbn)}, n veh: {len(veh)}, n sal: {len(sal)}\\n')\n",
    "                        f.write(f'hour {time} param {param} significant, p = {p}, stat = {stat}\\n')\n",
    "                        dunn_res = posthoc_dunn([cbn, veh, sal], p_adjust = 'bonferroni')\n",
    "                        dunn_res.columns = ['cbn','veh','sal']\n",
    "                        dunn_res.index = ['cbn','veh','sal']\n",
    "                        if (dunn_res <= 0.05).any().any():\n",
    "                            #check which groups were different\n",
    "                            print(dunn_res)                       \n",
    "                            for p_col in dunn_res.columns:\n",
    "                                for p_row in dunn_res.index:\n",
    "                                    p = dunn_res.loc[p_row, p_col]\n",
    "                                    if p < 0.05:\n",
    "                                        signif_times.append([time, p_row, p_col])\n",
    "                            f.write(dunn_res.to_string())\n",
    "                        else:\n",
    "                            print('posthoc ns')\n",
    "                            f.write('posthoc ns')\n",
    "                        f.write('\\n')\n",
    "        signif_params.append(signif_times)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['A', 'B', 'C', 'D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ch in chs:\n",
    "    fig, ax = plt.subplots(4,1,figsize = (10,10))\n",
    "    for i, param in enumerate(params):\n",
    "        sns.lineplot(data = time_medians.loc[(time_medians['channel'] == ch)], x = 'hour', y = param, hue = 'group', ax = ax[i], estimator = 'median', errorbar = 'ci')\n",
    "        # ax[i].set(ylim = (0,time_data.loc[(time_data['channel'] == ch)&(time_data['inj'] == inj), param].quantile(0.75)))\n",
    "        ax[i].tick_params(axis = 'x', labelrotation=90)\n",
    "        ax[i].set(xlabel = 'Time', ylabel = param_renaming_dict[param])\n",
    "        ax[i].legend(bbox_to_anchor=(0.35, 1.3), ncols = 3)\n",
    "        \n",
    "        xmin, xmax = ax[i].get_xlim()\n",
    "        ymin, ymax = ax[i].get_ylim()\n",
    "        \n",
    "        ax[i].vlines(0, ymin, ymax, colors='r', linestyles='--')\n",
    "        ax[i].vlines(24, ymin, ymax, colors='k', linestyles='--')\n",
    "        \n",
    "        cbn_veh = []\n",
    "        cbn_sal = []\n",
    "        veh_sal = []\n",
    "\n",
    "        #mark signif as lines\n",
    "        signif = np.array(signif_params[i], dtype=object)\n",
    "        for result in signif:\n",
    "            if result[1] == 'cbn' or result[2] == 'cbn':\n",
    "                if result[2] == 'veh' or result[1] == 'veh':\n",
    "                    cbn_veh.append(result[0])\n",
    "            if result[1] == 'cbn' or result[2] == 'cbn':\n",
    "                if result[2] == 'sal' or result[1] == 'sal':\n",
    "                    cbn_sal.append(result[0])\n",
    "            if result[1] == 'veh' or result[2] == 'veh':\n",
    "                if result[2] == 'sal' or result[1] == 'sal':\n",
    "                    veh_sal.append(result[0])\n",
    "        \n",
    "        #instead plot as text\n",
    "        for x in cbn_veh:\n",
    "            ax[i].text(x = x, y = ymax*0.75, s = '*', ha=\"center\", va=\"center\")\n",
    "        for x in cbn_sal:\n",
    "            ax[i].text(x = x, y = ymax*0.80, s = '°', ha=\"center\", va=\"center\")\n",
    "        for x in veh_sal:\n",
    "            ax[i].text(x = x, y = ymax*0.85, s = '^', ha=\"center\", va=\"center\")\n",
    "        \n",
    "        #add annotation\n",
    "        ax[i].annotate(letters[i], xy = (-ax[i].get_xlim()[1]*0.03, ax[i].get_ylim()[1]*0.8),  size = 15)\n",
    "        # for index, label in enumerate(ax[i].xaxis.get_ticklabels()):\n",
    "        #     if index % 6 != 0:\n",
    "        #         label.set_visible(False)\n",
    "    fig.suptitle(str(ch_renaming_dict[ch])+', median of all days', y = 0.97)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./plots/spectral_{ch}_medianbyhour.png', transparent = True, dpi = 300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_medians.groupby(['hour','channel','group']).agg(['median', q1, q3]).to_excel('./results/spectral_time_medians.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall per day\n",
    "time_medians['phase'] = 'Dark'\n",
    "time_medians.loc[(time_medians['hour'] >= '08:30')&(time_medians['hour'] < '20:30'), 'phase'] = 'Light'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "byphase = time_medians.groupby(['id','group','channel','phase']).median(numeric_only=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in chs:\n",
    "    fig, ax = plt.subplots(1,4, figsize = (10,5))\n",
    "    for i, param in enumerate(params):\n",
    "        sns.boxplot(data = byphase.loc[byphase['channel'] == ch], x = 'phase', y = param, ax = ax[i])\n",
    "        ax[i].set(xlabel = None, ylabel = param_renaming_dict[param])\n",
    "        if param == 'meanpowf':\n",
    "            ax[i].set(ylim = (22))\n",
    "        elif param == 'maxpow' or param == 'meanpow':\n",
    "            ax[i].set(ylim = (0-byphase.loc[byphase['channel'] == ch, param].quantile(0.5),byphase.loc[byphase['channel'] == ch, param].quantile(0.85) ))\n",
    "        # ax[i].legend(bbox_to_anchor=(1, 1.2), ncols = 2)\n",
    "    fig.suptitle(ch_renaming_dict[ch]+', median of all days')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./plots/spectral_{ch}_nogroup_lightdarkmedians.png', transparent = True, dpi = 300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats\n",
    "signif_params = []\n",
    "f = open('results/spectral_lightdark_median_stats.txt','w')\n",
    "for i, param in enumerate(params):\n",
    "    signif_times = []\n",
    "    for ch in chs:\n",
    "        for phase in byphase['phase'].unique():\n",
    "            light_subset = byphase.loc[(byphase['phase'] == phase)&(byphase['channel']==ch)]\n",
    "            cbn = light_subset[light_subset['group'] == 'cbn'][param].tolist()\n",
    "            veh = light_subset[light_subset['group'] == 'veh'][param].tolist()\n",
    "            sal = light_subset[light_subset['group'] == 'sal'][param].tolist()\n",
    "            \n",
    "            cbn = reject_outliers(cbn)\n",
    "            veh = reject_outliers(veh)\n",
    "            sal = reject_outliers(sal)\n",
    "            \n",
    "            if cbn and veh and sal:\n",
    "                if (np.sum(cbn) != np.sum(veh)) and (np.sum(cbn)!=np.sum(sal)):\n",
    "                    stat, p = stats.kruskal(cbn, veh, sal)\n",
    "                    if p < 0.05:\n",
    "                        print(f'n cbn: {len(cbn)}, n veh: {len(veh)}, n sal: {len(sal)}')\n",
    "                        print(f'{phase} phase, {ch} channel, param {param} significant, p = {p}, stat = {stat}')\n",
    "                        f.write(f'n cbn: {len(cbn)}, n veh: {len(veh)}, n sal: {len(sal)}\\n')\n",
    "                        f.write(f'{phase} phase, {ch} channel, param {param} significant, p = {p}, stat = {stat}')\n",
    "                        dunn_res = posthoc_dunn([cbn, veh, sal], p_adjust = 'bonferroni')\n",
    "                        dunn_res.columns = ['cbn','veh','sal']\n",
    "                        dunn_res.index = ['cbn','veh','sal']\n",
    "                        if (dunn_res <= 0.05).any().any():\n",
    "    #                         #check which groups were different\n",
    "                            print(dunn_res)                       \n",
    "                            for p_col in dunn_res.columns:\n",
    "                                for p_row in dunn_res.index:\n",
    "                                    p = dunn_res.loc[p_row, p_col]\n",
    "                                    if p < 0.05:\n",
    "                                        signif_times.append([phase, p_row, p_col])\n",
    "                            f.write(dunn_res.to_string())\n",
    "                        else:\n",
    "                            print('posthoc ns')\n",
    "                            f.write('posthoc ns')\n",
    "                        f.write('\\n')\n",
    "        signif_params.append(signif_times)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in chs:\n",
    "    fig, ax = plt.subplots(1,4, figsize = (10,5))\n",
    "    for i, param in enumerate(params):\n",
    "        sns.boxplot(data = byphase.loc[byphase['channel'] == ch], x = 'phase', y = param, hue = 'group', ax = ax[i])\n",
    "        ax[i].set(xlabel = None, ylabel = param_renaming_dict[param])\n",
    "        ax[i].legend(bbox_to_anchor=(1, 1.2), ncols = 2)\n",
    "        \n",
    "        ymin, ymax = ax[i].get_ylim()\n",
    "        xmin, xmax = ax[i].get_xlim()\n",
    "        \n",
    "        if param == 'meanpowf':\n",
    "            ax[i].set(ylim = (22))\n",
    "        \n",
    "        cbn_veh = []\n",
    "        cbn_sal = []\n",
    "        veh_sal = []\n",
    "\n",
    "        #mark signif as lines\n",
    "        signif = np.array(signif_params[i], dtype=object)\n",
    "        for result in signif:\n",
    "            if result[1] == 'cbn' or result[2] == 'cbn':\n",
    "                if result[2] == 'veh' or result[1] == 'veh':\n",
    "                    cbn_veh.append(result[0])\n",
    "            if result[1] == 'cbn' or result[2] == 'cbn':\n",
    "                if result[2] == 'sal' or result[1] == 'sal':\n",
    "                    cbn_sal.append(result[0])\n",
    "            if result[1] == 'veh' or result[2] == 'veh':\n",
    "                if result[2] == 'sal' or result[1] == 'sal':\n",
    "                    veh_sal.append(result[0])\n",
    "    \n",
    "        # #instead plot as text\n",
    "        y = ymax*0.9\n",
    "        h = y*0.01\n",
    "        offset = 0.25\n",
    "        for x in cbn_veh:\n",
    "            if x == 'Light':\n",
    "                xmin, xmax= 0-offset, 0, \n",
    "                ax[i].plot([xmin, xmin, xmax, xmax], [y, y+h, y+h, y], linewidth=1, c='k')\n",
    "                ax[i].text((xmin+xmax)*.5, y-h, \"*\", ha='center', va='bottom', color='k')\n",
    "            elif x == 'Dark':\n",
    "                xmin, xmax = 1-offset, 1\n",
    "                ax[i].plot([xmin, xmin, xmax, xmax], [y, y+h, y+h, y], linewidth=1, c='k')\n",
    "                ax[i].text((xmin+xmax)*.5, y-h, \"*\", ha='center', va='bottom', color='k')\n",
    "        for x in cbn_sal:\n",
    "            if x == 'Light':\n",
    "                xmin, xmax = 0, 0+offset\n",
    "                ax[i].plot([xmin, xmin, xmax, xmax], [y, y+h, y+h, y], linewidth=1, c='k')\n",
    "                ax[i].text((xmin+xmax)*.5, y-h, \"*\", ha='center', va='bottom', color='k')\n",
    "            elif x == 'Dark':\n",
    "                xmin, xmax = 1, 1+offset\n",
    "                ax[i].plot([xmin, xmin, xmax, xmax], [y, y+h, y+h, y], linewidth=1, c='k')\n",
    "                ax[i].text((xmin+xmax)*.5, y-h, \"*\", ha='center', va='bottom', color='k')\n",
    "        for x in veh_sal:\n",
    "            if x == 'Light':\n",
    "                xmin, xmax = 0-offset, 0+offset\n",
    "                ax[i].plot([xmin, xmin, xmax, xmax], [y, y+h, y+h, y], linewidth=1, c='k')\n",
    "                ax[i].text((xmin+xmax)*.5, y-h, \"*\", ha='center', va='bottom', color='k')\n",
    "            elif x == 'Dark':\n",
    "                xmin, xmax = 1-offset, 1+offset\n",
    "                ax[i].plot([xmin, xmin, xmax, xmax], [y, y+h, y+h, y], linewidth=1, c='k')\n",
    "                ax[i].text((xmin+xmax)*.5, y-h, \"*\", ha='center', va='bottom', color='k')\n",
    "        \n",
    "        \n",
    "    fig.suptitle(ch_renaming_dict[ch]+', median of all days')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./plots/spectral_{ch}_lightdarkmedians.png', transparent = True, dpi = 300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "byphase.groupby(['phase','channel','group']).agg(['median', q1, q3]).to_excel('./results/spectral_lightdark_medians.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEXT - continue with states\n",
    "#same issue - duplicated indices\n",
    "state_data[['maxpow', 'meanpow', 'maxpowf', 'meanpowf']] = state_data[['maxpow', 'meanpow', 'maxpowf', 'meanpowf']].astype(float)\n",
    "state_data = state_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data['inj'].unique()#.drop(['state_id','time'],axis = 1).groupby(['id','sleep','channel','group','inj']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping\n",
    "grouped = []\n",
    "for id in state_data['id'].unique():\n",
    "    for ch in state_data['channel'].unique():\n",
    "        id_subset = state_data.loc[(state_data['id']==id)&(state_data['channel']==ch)]\n",
    "        grouped.append(id_subset.groupby(['id','sleep','channel','group','inj']).median(numeric_only = True).reset_index().dropna())\n",
    "state_data = pd.concat(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#again no point\n",
    "# for ch in chs:\n",
    "#     fig, ax = plt.subplots(len(state_data['inj'].unique()), 4, figsize = (10,20))\n",
    "#     for i_row, inj in enumerate(state_data['inj'].unique()):\n",
    "#         for i_col, param in enumerate(params):\n",
    "#             sns.boxplot(data = state_data.loc[state_data['inj'] == inj], x = 'sleep', hue = 'group', y = param, ax = ax[i_row][i_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbn group n = 7\n",
      "veh group n = 7\n",
      "sal group n = 5\n"
     ]
    }
   ],
   "source": [
    "#check medians\n",
    "state_medians = state_data.groupby(['id','sleep','channel','group']).median(numeric_only=True).reset_index()\n",
    "n_cbn = len(state_medians[state_medians['group']=='cbn']['id'].unique())\n",
    "n_veh = len(state_medians[state_medians['group']=='veh']['id'].unique())\n",
    "n_sal = len(state_medians[state_medians['group']=='sal']['id'].unique())\n",
    "print(f'cbn group n = {n_cbn}')\n",
    "print(f'veh group n = {n_veh}')\n",
    "print(f'sal group n = {n_sal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in chs:\n",
    "    fig, ax = plt.subplots(1,4,figsize = (10,5))\n",
    "    for i, param in enumerate(params):\n",
    "        sns.boxplot(data = state_medians.loc[state_medians['channel']==ch], x = 'sleep', y = param, ax =ax[i])\n",
    "        ax[i].set(xlabel = None, ylabel = param_renaming_dict[param])\n",
    "        # ax[i].legend(bbox_to_anchor=(1, 1.2), ncols = 2)\n",
    "        if param == 'meanpowf':\n",
    "            ax[i].set(ylim = (20,32))\n",
    "    fig.suptitle(ch_renaming_dict[ch]+', median of all days')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./plots/spectral_{ch}_nogroups_bystate_medians.png', transparent = True, dpi = 300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats\n",
    "signif_params = []\n",
    "f = open('results/spectral_sleepstate_median_stats.txt','w')\n",
    "for i, param in enumerate(params):\n",
    "    signif_times = []\n",
    "    for ch in chs:\n",
    "        for phase in state_medians['sleep'].unique():\n",
    "            light_subset = state_medians.loc[(state_medians['sleep'] == phase)&(state_medians['channel']==ch)]\n",
    "            cbn = light_subset[light_subset['group'] == 'cbn'][param].tolist()\n",
    "            veh = light_subset[light_subset['group'] == 'veh'][param].tolist()\n",
    "            sal = light_subset[light_subset['group'] == 'sal'][param].tolist()\n",
    "            \n",
    "            cbn = reject_outliers(cbn)\n",
    "            veh = reject_outliers(veh)\n",
    "            sal = reject_outliers(sal)\n",
    "            \n",
    "            if cbn and veh and sal:\n",
    "                if (np.sum(cbn) != np.sum(veh)) and (np.sum(cbn)!=np.sum(sal)):\n",
    "                    stat, p = stats.kruskal(cbn, veh, sal)\n",
    "                    if p < 0.05:\n",
    "                        print(f'n cbn: {len(cbn)}, n veh: {len(veh)}, n sal: {len(sal)}')\n",
    "                        print(f'{phase} phase, {ch} channel, param {param} significant, p = {p}, stat = {stat}')\n",
    "                        f.write(f'n cbn: {len(cbn)}, n veh: {len(veh)}, n sal: {len(sal)}\\n')\n",
    "                        f.write(f'{phase} phase, {ch} channel, param {param} significant, p = {p}, stat = {stat}')\n",
    "                        dunn_res = posthoc_dunn([cbn, veh, sal], p_adjust = 'bonferroni')\n",
    "                        dunn_res.columns = ['cbn','veh','sal']\n",
    "                        dunn_res.index = ['cbn','veh','sal']\n",
    "                        if (dunn_res <= 0.05).any().any():\n",
    "    #                         #check which groups were different\n",
    "                            print(dunn_res)                       \n",
    "                            for p_col in dunn_res.columns:\n",
    "                                for p_row in dunn_res.index:\n",
    "                                    p = dunn_res.loc[p_row, p_col]\n",
    "                                    if p < 0.05:\n",
    "                                        signif_times.append([phase, p_row, p_col])\n",
    "                            f.write(dunn_res.to_string())\n",
    "                        else:\n",
    "                            print('posthoc ns')\n",
    "                            f.write('posthoc ns')\n",
    "                        f.write('\\n')\n",
    "        signif_params.append(signif_times)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signif_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in chs:\n",
    "    fig, ax = plt.subplots(1,4,figsize = (10,5))\n",
    "    for i, param in enumerate(params):\n",
    "        sns.boxplot(data = state_medians.loc[state_medians['channel']==ch], x = 'sleep', y = param, hue = 'group', ax =ax[i])\n",
    "        ax[i].set(xlabel = None, ylabel = param_renaming_dict[param])\n",
    "        ax[i].legend(bbox_to_anchor=(1, 1.2), ncols = 2)\n",
    "        if param == 'meanpowf':\n",
    "            ax[i].set(ylim = (20,32))\n",
    "        \n",
    "        ymin, ymax = ax[i].get_ylim()\n",
    "        xmin, xmax = ax[i].get_xlim()\n",
    "        \n",
    "        if param == 'meanpowf':\n",
    "            ax[i].set(ylim = (22))\n",
    "        \n",
    "        cbn_veh = []\n",
    "        cbn_sal = []\n",
    "        veh_sal = []\n",
    "\n",
    "        #mark signif as lines\n",
    "        signif = np.array(signif_params[i], dtype=object)\n",
    "        for result in signif:\n",
    "            if result[1] == 'cbn' or result[2] == 'cbn':\n",
    "                if result[2] == 'veh' or result[1] == 'veh':\n",
    "                    cbn_veh.append(result[0])\n",
    "            if result[1] == 'cbn' or result[2] == 'cbn':\n",
    "                if result[2] == 'sal' or result[1] == 'sal':\n",
    "                    cbn_sal.append(result[0])\n",
    "            if result[1] == 'veh' or result[2] == 'veh':\n",
    "                if result[2] == 'sal' or result[1] == 'sal':\n",
    "                    veh_sal.append(result[0])\n",
    "    \n",
    "        # #instead plot as text\n",
    "        y = ymax*0.9\n",
    "        h = y*0.01\n",
    "        offset = 0.25\n",
    "        for x in cbn_veh:\n",
    "            if x == 'N':\n",
    "                xmin, xmax= 0-offset, 0, \n",
    "                ax[i].plot([xmin, xmin, xmax, xmax], [y, y+h, y+h, y], linewidth=1, c='k')\n",
    "                ax[i].text((xmin+xmax)*.5, y-h, \"*\", ha='center', va='bottom', color='k')\n",
    "            elif x == 'W':\n",
    "                xmin, xmax = 2-offset, 2\n",
    "                ax[i].plot([xmin, xmin, xmax, xmax], [y, y+h, y+h, y], linewidth=1, c='k')\n",
    "                ax[i].text((xmin+xmax)*.5, y-h, \"*\", ha='center', va='bottom', color='k')\n",
    "            elif x == 'R':\n",
    "                xmin, xmax = 1-offset, 1\n",
    "                ax[i].plot([xmin, xmin, xmax, xmax], [y, y+h, y+h, y], linewidth=1, c='k')\n",
    "                ax[i].text((xmin+xmax)*.5, y-h, \"*\", ha='center', va='bottom', color='k')\n",
    "        for x in cbn_sal:\n",
    "            if x == 'N':\n",
    "                xmin, xmax= 0+offset, 0, \n",
    "                ax[i].plot([xmin, xmin, xmax, xmax], [y, y+h, y+h, y], linewidth=1, c='k')\n",
    "                ax[i].text((xmin+xmax)*.5, y-h, \"*\", ha='center', va='bottom', color='k')\n",
    "            elif x == 'W':\n",
    "                xmin, xmax = 2+offset, 2\n",
    "                ax[i].plot([xmin, xmin, xmax, xmax], [y, y+h, y+h, y], linewidth=1, c='k')\n",
    "                ax[i].text((xmin+xmax)*.5, y-h, \"*\", ha='center', va='bottom', color='k')\n",
    "            elif x == 'R':\n",
    "                xmin, xmax = 1+offset, 1\n",
    "                ax[i].plot([xmin, xmin, xmax, xmax], [y, y+h, y+h, y], linewidth=1, c='k')\n",
    "                ax[i].text((xmin+xmax)*.5, y-h, \"*\", ha='center', va='bottom', color='k')\n",
    "        for x in veh_sal:\n",
    "            if x == 'N':\n",
    "                xmin, xmax= 0-offset, 0+offset, \n",
    "                ax[i].plot([xmin, xmin, xmax, xmax], [y, y+h, y+h, y], linewidth=1, c='k')\n",
    "                ax[i].text((xmin+xmax)*.5, y-h, \"*\", ha='center', va='bottom', color='k')\n",
    "            elif x == 'W':\n",
    "                xmin, xmax = 2-offset, 2+offset\n",
    "                ax[i].plot([xmin, xmin, xmax, xmax], [y, y+h, y+h, y], linewidth=1, c='k')\n",
    "                ax[i].text((xmin+xmax)*.5, y-h, \"*\", ha='center', va='bottom', color='k')\n",
    "            elif x == 'R':\n",
    "                xmin, xmax = 1-offset, 1+offset\n",
    "                ax[i].plot([xmin, xmin, xmax, xmax], [y, y+h, y+h, y], linewidth=1, c='k')\n",
    "                ax[i].text((xmin+xmax)*.5, y-h, \"*\", ha='center', va='bottom', color='k')\n",
    "         \n",
    "            \n",
    "    fig.suptitle(ch_renaming_dict[ch]+', median of all days')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./plots/spectral_{ch}_bystate_medians.png', transparent = True, dpi = 300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to excel\n",
    "state_medians.groupby(['sleep','channel','group']).agg(['median', q1, q3]).to_excel('./results/spectral_bystate_medians.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basicdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
