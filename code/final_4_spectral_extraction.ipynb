{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#required packages\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from scipy import signal, stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "#my funcs\n",
    "from ecog_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global params\n",
    "SAMPLE_RATE = 1000\n",
    "VERBOSE = False\n",
    "OVERWRITE = False\n",
    "DATA_SUFFIX = 'spectral_final'\n",
    "SAVING_PATH = r'C:\\Users\\marty\\Projects\\sleep_new\\res_temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis function \n",
    "# remember to apply to a single channel and:\n",
    "# only if subset len > 5 s for sleep, == 5 min for time\n",
    "def get_spectral_params(subset, sr = SAMPLE_RATE):\n",
    "\n",
    "    f, pxx = signal.periodogram(subset, fs = sr)\n",
    "    maxpow = np.max(pxx)\n",
    "    meanpow = np.mean(pxx)\n",
    "\n",
    "    #get difference from mean for each power\n",
    "    dmean = np.abs(pxx-meanpow)\n",
    "    meanpowf = f[np.argmin(dmean)]\n",
    "\n",
    "    #get difference from max for each power\n",
    "    dmax = np.abs(pxx-maxpow)\n",
    "    maxpowf = f[np.argmin(dmax)]\n",
    "\n",
    "    return maxpow, meanpow, maxpowf, meanpowf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sorted sleep states\n",
    "sorted =  pickle.load(open('./res_temp/sleep_sorted_data4.pkl', 'rb'))\n",
    "#keep time, ID, and sleep\n",
    "sorted = sorted[['id','sleep']]\n",
    "#fix IDs\n",
    "rename_id = {'5_':'5','6_':'6','7_':'7','8_':8}\n",
    "sorted['id'] = sorted['id'].replace(rename_id).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths - single hour\n",
    "PATHS = glob.glob(r\"G:\\DATA\\tween_cbn_sleep\\*\\timestamped\\*.txt\")\n",
    "EXTRA_PATHS = r\"C:\\Users\\marty\\Documents\\DATA\\water_soluble_cbn_sleep\\*\\timestamped\\*.txt\"\n",
    "PATHS.extend(glob.glob(EXTRA_PATHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_exclude = [41, 51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set days so not all data is read\n",
    "valid_days = ['20241703','20241803','20241903','20242003','20242103','20242203','20242303','20242403','20242503','20242603','20242703','20242803','20242903','20243003','20240104','20240204','20240304','20240404','20240504','20240604',\n",
    "              '20242202','20242302','20242402','20242502','20242602','20242702','20242802','20242902','20240103','20240203','20240303','20240403','20240503', '20241103','20241203','20241303','20241403','20241503',\n",
    "              '20230711','20230811','20230911','20231011','20231111','20231211','20231311','20231411','20231511','20231611','20231711','20231811','20231911', '20230112','20230212','20230312','20230412',\n",
    "              '20232912','20233012','20233112','20240101','20240201','20240301','20240401','20240501','20240601','20240801','20240901','20241001','20241101','20241201','20241301','20241401','20241501','20242001','20242101','20242201','20242301','20242401','20242501','20242601',\n",
    "              '20230504','20230604','20230704','20230804','20230904','20231004','20231104','20232705','20232805','20232905''20233005','20233105','20230106','20230206','20230306','20230406','20230506','20230606','20230706','20230806','20230906','20231006','20232206', '20232306', '20232406', '20232506', '20232606']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in tqdm(PATHS):\n",
    "    id = int(path.split('\\\\')[-3])\n",
    "    #check if ID is included\n",
    "    if id in to_exclude:\n",
    "        continue\n",
    "    \n",
    "    #check if path is in days\n",
    "    if path.split('\\\\')[-1][:8] not in valid_days:\n",
    "        continue\n",
    "    \n",
    "    #read file\n",
    "    try:\n",
    "        info = pd.read_csv(path, nrows=8, header = None)\n",
    "        day = info.loc[0].str.strip('date:').astype(str)[0]\n",
    "        hour = info.loc[1].str.strip('time:').astype(str)[0]\n",
    "        date = pd.to_datetime(day + hour)\n",
    "    except:\n",
    "        if VERBOSE:\n",
    "            print(f'file {path} read failed!')\n",
    "        continue\n",
    "    \n",
    "    #now check if savepath exists\n",
    "    date_save = str(date).replace(' ','_').replace(':','_')\n",
    "    savepath = SAVING_PATH+f'\\{id}_{date_save}_'+DATA_SUFFIX\n",
    "    if not OVERWRITE:\n",
    "        if os.path.isfile(savepath+'_state.pkl') or os.path.isfile(savepath+'_time.pkl'):\n",
    "            if VERBOSE:\n",
    "                print(f'{savepath} exists, skipping')\n",
    "            continue\n",
    "               \n",
    "    try:\n",
    "        data = pd.read_csv(path, skiprows=9, header=None)\n",
    "        data = data.loc[:,0].str.split(' ', expand = True)\n",
    "    except:\n",
    "        if VERBOSE:\n",
    "            print(f'file {path} read failed!')\n",
    "        continue\n",
    "    \n",
    "    #now check len of data - keep only if half-hour available from the hour\n",
    "    if len(data) < 180000:\n",
    "        if VERBOSE:\n",
    "            print(f'incomplete rec for {id} {date}')\n",
    "        continue\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(f'CHECKS PASSED, DATA READ: rat {id}, rec {date}')\n",
    "        \n",
    "    #now create time array\n",
    "    time = pd.date_range(start=date, periods=len(data),freq='1ms')\n",
    "    #subset sleep states by ID and time\n",
    "    sleep_subset = sorted.loc[(sorted['id'] == id)&sorted.index.isin(time)]\n",
    "    #remove duplicated indices\n",
    "    sleep_subset = sleep_subset[~sleep_subset.index.duplicated(keep='first')]\n",
    "    \n",
    "    #now check if there is enough data in sleep states - keep only if 30 mins available\n",
    "    if len(sleep_subset) < 1800:\n",
    "        if VERBOSE:\n",
    "            print(f'incomplete sleep states for {id} {date}')\n",
    "        continue\n",
    "    \n",
    "    #set index of data\n",
    "    data.index = time\n",
    "    #convert to numeric\n",
    "    try:\n",
    "        data = convert_to_mv(data)\n",
    "    except:\n",
    "        if VERBOSE:\n",
    "            print(f'CONVERSION ERROR, rat {id}, rec {date}')\n",
    "        continue\n",
    "    #filter data\n",
    "    filtered_data=pd.DataFrame()\n",
    "    filtered_data['l_ecog']=filter_channel(data['l_ecog'], fstart=0.5, fstop=45, sr=SAMPLE_RATE, center=True, notch_50=False)\n",
    "    filtered_data['r_ecog']=filter_channel(data['r_ecog'], fstart=0.5, fstop=45, sr=SAMPLE_RATE, center=True, notch_50=False)\n",
    "    filtered_data['lfp']=filter_channel(data['lfp'], fstart=0.5, fstop=45, sr=SAMPLE_RATE, center=True, notch_50=False)\n",
    "    filtered_data['emg']=filter_channel(data['emg'], fstart=0.5, fstop=45, sr=SAMPLE_RATE, center=True, notch_50=True)\n",
    "    filtered_data.index=data.index\n",
    "    data = filtered_data\n",
    "    #now join sleep states to data\n",
    "    data['sleep'] = sleep_subset['sleep']\n",
    "    #drop missing rows\n",
    "    data = data.ffill().dropna()\n",
    "    #get 5 min subsets\n",
    "    data['time_adj'] = data.index.round('5min') \n",
    "    #get sleep state ids\n",
    "    data['state_id'] = np.cumsum(np.abs(data['sleep'].replace({'W':0,'N':1,'R':2}).diff().fillna(0)))\n",
    "    \n",
    "    #do analysis by time\n",
    "    if VERBOSE:\n",
    "        print(f'ANALYSIS BY TIME STARTED: rat {id}, rec {date}')\n",
    "    res_by_time = []\n",
    "    times = data['time_adj'].unique()\n",
    "    for time in times:\n",
    "        #subset data\n",
    "        data_sub = data.loc[data['time_adj'] == time]\n",
    "        if len(data_sub) < 300000:\n",
    "            if VERBOSE:\n",
    "                print('not enough data, time subset')\n",
    "            continue\n",
    "        channels = ['l_ecog','r_ecog','lfp','emg']\n",
    "        for channel in channels:\n",
    "            maxpow, meanpow, maxpowf, meanpowf = get_spectral_params(data_sub[channel], sr = SAMPLE_RATE)\n",
    "            #now save to res list\n",
    "            res_row = pd.DataFrame([id, time, channel, maxpow, meanpow, maxpowf, meanpowf]).T\n",
    "            res_row.columns = ['id','time','channel','maxpow','meanpow','maxpowf','meanpowf']\n",
    "            res_by_time.append(res_row)\n",
    "    if len(res_by_time)>0:\n",
    "        pickle.dump(pd.concat(res_by_time), open(savepath+'_time.pkl', 'wb'))\n",
    "    else:\n",
    "        print('results not generated')\n",
    "    print(f'ANALYSIS BY TIME DONE: rat {id}, rec {date}')\n",
    "    \n",
    "    #do analysis by state\n",
    "    if VERBOSE:\n",
    "        print(f'ANALYSIS BY STATE STARTED: rat {id}, rec {date}')\n",
    "    res_by_state = []    \n",
    "    state_ids = data['state_id'].unique()\n",
    "    for state_id in state_ids:\n",
    "        #get subset\n",
    "        data_sub = data.loc[data['state_id']==state_id]\n",
    "        #check if more than 5 seconds of the state are available\n",
    "        if len(data_sub) < 5000:\n",
    "            if VERBOSE:\n",
    "                print('not enough data, state subset')\n",
    "            continue\n",
    "        #if more is available, get results\n",
    "        channels = ['l_ecog','r_ecog','lfp','emg']\n",
    "        for channel in channels:\n",
    "            maxpow, meanpow, maxpowf, meanpowf = get_spectral_params(data_sub[channel], sr = SAMPLE_RATE)\n",
    "            #now save to res list\n",
    "            res_row = pd.DataFrame([id, state_id, data_sub.index[0], data_sub['sleep'].iloc[0], channel, maxpow, meanpow, maxpowf, meanpowf]).T\n",
    "            res_row.columns = ['id','state_id','time','sleep','channel','maxpow','meanpow','maxpowf','meanpowf']\n",
    "            res_by_state.append(res_row)\n",
    "    if len(res_by_state)>0:\n",
    "        pickle.dump(pd.concat(res_by_state), open(savepath+'_state.pkl', 'wb'))\n",
    "    else:\n",
    "        print('results not generated')\n",
    "    print(f'ANALYSIS BY STATE DONE: rat {id}, rec {date}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basicdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
