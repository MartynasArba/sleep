{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c8f42b-fd56-4c01-ad87-9f39fc4bdddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "#req packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "#edf\n",
    "import mne\n",
    "#myfuncs\n",
    "from ecog_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9300f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to center and filter the data\n",
    "def filter_channel(channel, fstart=0.1, fstop=45, sr=1000, center=True, notch_50=False):\n",
    "    \"\"\"A function to perform notch filtering, mean centering and bandpass filtering for a single recorded channel. \n",
    "    \n",
    "    Args:\n",
    "        channel (pandas series/column): A single column from the recording.\n",
    "        fstart (float, optional): The low end of the range to return. Defaults to 0.1.\n",
    "        fstop (int, optional): The high end of the range to return. Defaults to 45.\n",
    "        sr (int, optional): Sampling rate of the recording. Defaults to 1000.\n",
    "        center (bool, optional): Should centering be performed. Defaults to True.\n",
    "        notch_50 (bool, optional): Should a 50 Hz Notch filter be applied. Defaults to False, because by default 50 Hz is already out of range.\n",
    "\n",
    "    Returns:\n",
    "        Output of the filtering function: a filtered channel.\n",
    "    \"\"\"\n",
    "    if center==True:\n",
    "        channel=channel-channel.mean()\n",
    "        \n",
    "    if notch_50==True:\n",
    "        b0, a0=signal.iirnotch(50, Q=30, fs=sr)\n",
    "        channel=signal.filtfilt(b0, a0, channel)\n",
    "    \n",
    "    sos_bandpass=signal.butter(N=20, Wn=(fstart, fstop), btype='bp', output='sos',  fs=sr)\n",
    "    \n",
    "    return signal.sosfiltfilt(sos_bandpass, channel) \n",
    "\n",
    "def sort_cls_by_criteria(grouped):\n",
    "    \"\"\"Sorts clusters by a decision tree. \n",
    "    Splits by EMG, then by alpha*delta, then beta*gamma, then theta - needs an update\n",
    "    Modify this function to modify results\n",
    "\n",
    "    Args:\n",
    "        grouped (dataframe): dataframe of clusters and their median parameters\n",
    "\n",
    "    Returns:\n",
    "        w_cls: clusters marked as wake\n",
    "        same for other outputs\n",
    "    \"\"\"\n",
    "        \n",
    "    w_cls = []\n",
    "    nrem_cls = []\n",
    "    rem_cls = []\n",
    "    \n",
    "    unsorted_cls = grouped.index\n",
    "    for cluster in unsorted_cls:\n",
    "        #option 5 - HIGH or not, no ratios\n",
    "        nonzero = grouped.iloc[:,0:6]>grouped.iloc[:,0:6].quantile(0.25)\n",
    "        high = grouped.iloc[:,0:6]>grouped.iloc[:,0:6].quantile(0.5)\n",
    "        very_high = grouped.iloc[:,0:6]>grouped.iloc[:,0:6].quantile(0.75)\n",
    "        #NREM\n",
    "        #if not high['emg'][cluster]:\n",
    "        if high['delta'][cluster] or high['alpha'][cluster] or high['theta'][cluster]:\n",
    "            if very_high['theta'][cluster] and (nonzero['beta'][cluster] and nonzero['gamma'][cluster]) and not nonzero['emg'][cluster]:\n",
    "                rem_cls.append(cluster)\n",
    "            elif (high['delta'][cluster] or high['alpha'][cluster] or high['theta'][cluster]) and not high['emg'][cluster]:\n",
    "                nrem_cls.append(cluster)\n",
    "            else:\n",
    "                w_cls.append(cluster)\n",
    "        else:\n",
    "            w_cls.append(cluster)\n",
    "    #make sure there is at least one REM cluster detected\n",
    "    #if there are no REM clusters, select the one with highest theta, lowest emg and nonzero beta/gamma\n",
    "    if not rem_cls:\n",
    "        #scale gr to allow index calculation\n",
    "        grouped.iloc[:,:-2] = minmax_scale(grouped.iloc[:,:-2])\n",
    "        #rem index\n",
    "        rem_ind = (grouped['theta']**2 * grouped['beta']*grouped['gamma'])/(grouped['emg']**2)\n",
    "        rem_cls.append(np.where(rem_ind == rem_ind.max())[0][0])\n",
    "        \n",
    "    return w_cls, nrem_cls, rem_cls\n",
    "\n",
    "def integrate_by_mode(data, integration_s = 5):\n",
    "    \"\"\"Integrates data by the mode of selected interval - replaces all values with the most common. \n",
    "    Works as a rolling filter.\n",
    "\n",
    "    Args:\n",
    "        data (pandas series): data of sleep detections (in this case) - N, R, and W categories. \n",
    "        integration_s (int, optional): size of window. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        res_sleep: list of updated results.\n",
    "    \"\"\"\n",
    "    #temporal integration - select most common state in set s to drop a bit of noise\n",
    "    res_sleep=[]\n",
    "    #nans bfilled - should figure out a better method, ran out of time\n",
    "    raw_sleep=data.reset_index(drop=True).fillna(method='bfill')\n",
    "    for i in tqdm(range(0, len(raw_sleep)-integration_s)):\n",
    "        #take most common value in 5s if it exists (not NaN)\n",
    "        mode = raw_sleep[i:i+integration_s].mode()[0]\n",
    "        #print(mode)\n",
    "        if mode !=0:\n",
    "            res_sleep.append(mode[0])\n",
    "        else:\n",
    "            print('weird error, mode=0')\n",
    "    return res_sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d8a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read paths of data published in https://zenodo.org/records/5227351\n",
    "paths = glob.glob(r'C:\\Users\\marty\\Downloads\\5227351\\*.edf')\n",
    "#manual scores path\n",
    "mansc_path = r\"C:\\Users\\marty\\Downloads\\5227351\\manual_scoring_all_rats.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fea5c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#glob params\n",
    "SAMPLE_RATE = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5d02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load manual labels\n",
    "all_human_labels  = pd.read_csv(mansc_path)\n",
    "all_human_labels.columns = all_human_labels.iloc[0].str.strip(\"'\")\n",
    "all_human_labels = all_human_labels.iloc[1:-1,1:]\n",
    "all_human_labels = all_human_labels.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8092b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "bad = 0\n",
    "\n",
    "for path in tqdm(paths):\n",
    "    #numerical IDs do repeat, so a partial string value is included\n",
    "    id = path[-16:-4]\n",
    "    rat_human_labeled = all_human_labels[[col for col in all_human_labels.columns if id in col]]\n",
    "    print(f'id is :{id}')\n",
    "    print(rat_human_labeled.columns)\n",
    "    data = mne.io.read_raw_edf(path)\n",
    "    #get relevant info\n",
    "    raw_data = data.get_data()\n",
    "    channels = data.ch_names\n",
    "    #discard data with shitty electrodes or unclear placement\n",
    "    if 'frontal' not in channels and 'EEG 1 frontal' not in channels and 'FRONTAL' not in channels:\n",
    "        print('shitty labeling')\n",
    "        bad += 1\n",
    "        continue    \n",
    "    \n",
    "    #convert to dataframe\n",
    "    data_df = pd.DataFrame(raw_data).T\n",
    "    data_df.columns = channels\n",
    "    \n",
    "    #now try to apply my method to this data\n",
    "    #only taking EMG and frontal for analysis\n",
    "    if 'EEG 1 frontal' in channels:\n",
    "        frontal = 'EEG 1 frontal' \n",
    "    elif 'frontal' in channels:\n",
    "        frontal = 'frontal' \n",
    "    elif 'FRONTAL' in channels:\n",
    "        frontal = 'FRONTAL' \n",
    "    else:\n",
    "        print('no frontal in channels')\n",
    "        continue\n",
    "    \n",
    "    if 'EMG' in channels:\n",
    "        emg = 'EMG'\n",
    "    elif 'EMG real' in channels:\n",
    "        emg = 'EMG real'\n",
    "    else:\n",
    "        print('no emg in channels')\n",
    "        continue\n",
    "    \n",
    "    #filtering\n",
    "    filtered_data=pd.DataFrame()\n",
    "    filtered_data['ecog']=filter_channel(data_df[frontal], fstart=0.5, fstop=45, sr=SAMPLE_RATE, center=True, notch_50=False)\n",
    "    filtered_data['emg']=filter_channel(data_df[emg], fstart=5, fstop=100, sr=SAMPLE_RATE, center=True, notch_50=True)\n",
    "    filtered_data.index=data_df.index\n",
    "    #get spectral components\n",
    "    BANDWIDTHS = {\n",
    "        'delta': (0.5, 4),\n",
    "        'theta': (4, 8),\n",
    "        'alpha': (8, 13),\n",
    "        'beta': (13, 30),\n",
    "        'gamma': (30, 45)\n",
    "    }\n",
    "\n",
    "    #create filters\n",
    "    bandwidth_filters = {\n",
    "        name: signal.butter(N=20, Wn=frange, btype='bp', output='sos',  fs=SAMPLE_RATE)\n",
    "        for name, frange in BANDWIDTHS.items()\n",
    "    }\n",
    "    #create output df\n",
    "    freq_comps=pd.DataFrame()\n",
    "    freq_comps.index=filtered_data.index\n",
    "    #split to freq comps\n",
    "    for i, (b, filter) in enumerate(bandwidth_filters.items()):\n",
    "        freq_comps[str(b)] = signal.sosfiltfilt(filter, filtered_data['ecog'])\n",
    "    #add emg\n",
    "    freq_comps['emg']=filtered_data['emg']\n",
    "\n",
    "    #convert to power - result is 4 s intervals\n",
    "    pows = []\n",
    "    index = []\n",
    "    for col in freq_comps.columns:\n",
    "        pow,ind,var = signal_to_power(freq_comps[col], window=1000)\n",
    "        pows.append(pow)\n",
    "        index.append(ind)\n",
    "    freq_powers = pd.DataFrame(pows).T\n",
    "    freq_powers.columns = freq_comps.columns\n",
    "    freq_powers.index = index[0]\n",
    "    print('FREQ POWERS OBTAINED')\n",
    "    #get power ratios\n",
    "    #convert to relative power - take each row and divide it by the sum of that row\n",
    "    #ignore EMG since it's not cortical and has different values - is basically always max if included\n",
    "    RELATIVE = True\n",
    "    if RELATIVE:\n",
    "        for ind in freq_powers.index:\n",
    "            freq_powers.loc[ind,freq_powers.columns[:-1]]=freq_powers.loc[ind,freq_powers.columns[:-1]]/freq_powers.loc[ind,freq_powers.columns[:-1]].sum()\n",
    "\n",
    "    #also standardize cols\n",
    "    scaler = StandardScaler()\n",
    "    freq_powers[freq_powers.columns]=scaler.fit_transform(freq_powers[freq_powers.columns])\n",
    "\n",
    "    #apply a rolling median filter 60 points\n",
    "    freq_powers = freq_powers.rolling(60).median()#.fillna(method='bfill',inplace=True)\n",
    "    freq_powers = freq_powers.bfill()\n",
    "\n",
    "    #code for training a new clusterer\n",
    "    MODE = 'train'\n",
    "    if MODE == 'train':\n",
    "        #try clustering \n",
    "        X = freq_powers.values\n",
    "        #select subset to save memory\n",
    "        idx = np.random.randint(len(X), size=50000)\n",
    "        subset=X[idx]\n",
    "\n",
    "        clusterer = AgglomerativeClustering(n_clusters=50, linkage='ward')\n",
    "        cluster_labels = clusterer.fit_predict(subset)\n",
    "\n",
    "        # inductive learning model to replicate agglomerative clustering on new data - way more efficient\n",
    "        classifier = RandomForestClassifier(random_state=42)\n",
    "        inductive_learner = InductiveClusterer(clusterer, classifier).fit(X)\n",
    "\n",
    "        #predictions from inductive clusterer\n",
    "        freq_powers['cluster']=inductive_learner.predict(X)\n",
    "        freq_powers['cluster']=freq_powers['cluster'].astype('category')\n",
    "    print('CLUSTERER TRAINED')\n",
    "    #now sort cls\n",
    "    gr=freq_powers[['delta','theta','alpha','beta','gamma','emg','cluster']].groupby('cluster', observed = False).mean()\n",
    "    gr['cluster']=freq_powers[['delta','theta','alpha','beta','gamma','emg','cluster']].groupby('cluster', observed = False).mean().index\n",
    "    gr['sleep']='unknown'\n",
    "    #run a cluster sorting function\n",
    "    w_cls, nrem_cls, rem_cls = sort_cls_by_criteria(gr)\n",
    "    #add back to data\n",
    "    #add sleep states to data\n",
    "    freq_powers['sleep']='unknown'\n",
    "    freq_powers.loc[freq_powers['cluster'].isin(w_cls), 'sleep'] = 'W'\n",
    "    freq_powers.loc[freq_powers['cluster'].isin(nrem_cls), 'sleep'] = 'N'\n",
    "    freq_powers.loc[freq_powers['cluster'].isin(rem_cls), 'sleep'] = 'R'\n",
    "    freq_powers = freq_powers.ffill()\n",
    "    freq_powers\n",
    "\n",
    "    #remove REM detections if they follow W\n",
    "    for i in range(0, len(freq_powers['sleep'])):\n",
    "        if (i>=5) and (freq_powers['sleep'].iloc[i]=='R'):\n",
    "            if 'W' in freq_powers['sleep'].iloc[i-5:i].tolist():\n",
    "                freq_powers['sleep'].iloc[i]='W'\n",
    "\n",
    "    freq_powers = freq_powers.reset_index(drop = True)\n",
    "    freq_powers['human_labeled'] = rat_human_labeled[0:len(freq_powers)].to_numpy()\n",
    "    freq_powers['human_labeled'] = freq_powers['human_labeled'].replace({0:'W',1:'N',2:'R'})\n",
    "    freq_powers['id'] = id\n",
    "    results.append(freq_powers)\n",
    "    print(f'RAT {id} DONE')\n",
    "print(f'num recs analyzed: {len(paths)-shitty}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84a774d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pd.concat(results), open('./res_temp/human_comparison.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc43488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle.load(open('./res_temp/human_comparison.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3f6b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redo sleep sorting here if want to - needs to be done by rat\n",
    "#messing with params doesn't really help\n",
    "for rat in results['id'].unique():\n",
    "    results.loc[results['id']==rat, 'sleep'] = results.loc[results['id']==rat, 'sleep'].replace({0:'W',1:'N',2:'R'})\n",
    "    gr=results.loc[results['id']==rat,['delta','theta','alpha','beta','gamma','emg','cluster']].groupby('cluster', observed = False).mean()\n",
    "    gr['cluster']=results.loc[results['id']==rat,['delta','theta','alpha','beta','gamma','emg','cluster']].groupby('cluster', observed = False).mean().index\n",
    "    gr['sleep']='unknown'\n",
    "    #run a cluster sorting function\n",
    "    w_cls, nrem_cls, rem_cls = sort_cls_by_criteria_alt(gr)\n",
    "    #add back to data\n",
    "    #add sleep states to data\n",
    "    results.loc[results['id']==rat,'sleep']='unknown'\n",
    "    results.loc[(results['id']==rat)&(results['cluster'].isin(w_cls)), 'sleep'] = 'W'\n",
    "    results.loc[(results['id']==rat)&(results['cluster'].isin(nrem_cls)), 'sleep'] = 'N'\n",
    "    results.loc[(results['id']==rat)&(results['cluster'].isin(rem_cls)), 'sleep'] = 'R'\n",
    "results = results.ffill()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7a2dce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7479304597435067"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#non-smoothened\n",
    "(results['sleep']==results['human_labeled']).sum()/len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77877354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smoothing\n",
    "for rat in results['id'].unique():\n",
    "    # results.loc[results['id']==rat, 'human_labeled'] = results.loc[results['id']==rat, 'human_labeled'].replace({0:'W',1:'N',2:'R'})\n",
    "    results.loc[results['id']==rat, 'sleep'] = results.loc[results['id']==rat, 'sleep'].replace({0:'W',1:'N',2:'R'})\n",
    "    \n",
    "    integration_s = 5\n",
    "    # results.loc[results['id']==rat, 'human_labeled']=pd.Series(integrate_by_mode(results.loc[results['id']==rat, 'human_labeled'], integration_s=integration_s))\n",
    "    results.loc[results['id']==rat, 'sleep'] = pd.Series(integrate_by_mode(results.loc[results['id']==rat, 'sleep'], integration_s=integration_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed88d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smoothened\n",
    "results = results.dropna()\n",
    "(results['sleep']==results['human_labeled']).sum()/len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f8743a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv sleep states to category\n",
    "from pandas.api.types import CategoricalDtype\n",
    "cat_dtype = CategoricalDtype(categories = ['W','N','R'], ordered = True)\n",
    "results['sleep'] = results['sleep'].astype(cat_dtype)\n",
    "results['human_labeled'] = results['human_labeled'].astype(cat_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa25f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#by rat\n",
    "for rat in results['id'].unique():\n",
    "    print((results.loc[results['id']==rat, 'sleep'] == results.loc[results['id']==rat, 'human_labeled']).sum()/len(results.loc[results['id']==rat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba2976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full evaluation\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "y_true = results['human_labeled'].dropna()\n",
    "y_pred = results['sleep'].dropna()\n",
    "# Example true labels and predicted labels for a multiclass classification problem\n",
    "\n",
    "# Calculate precision, recall, and F1 score for each class\n",
    "precision_per_class = precision_score(y_true, y_pred, average=None, labels = ['W','N','R'])\n",
    "recall_per_class = recall_score(y_true, y_pred, average=None)\n",
    "f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy: {accuracy}\\n')\n",
    "\n",
    "# # Print class-wise metrics\n",
    "print(\"Class-wise Metrics:\")\n",
    "for i in range(len(precision_per_class)):\n",
    "    print(\"Class {}: Precision={}, Recall={}, F1 Score={}\".format(i, precision_per_class[i], recall_per_class[i], f1_per_class[i]))\n",
    "\n",
    "# # Calculate and print confusion matrix\n",
    "# plt.set_cmap('bwr')\n",
    "conf_matrix = confusion_matrix(y_true, y_pred, labels = ['W','N','R'], normalize = 'true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,display_labels=['W','N','R'])\n",
    "disp.plot()\n",
    "disp.ax_.set(xlabel='Automatically predicted label', ylabel='Human label')#('Automatically predicted label')#,ylabel = 'Human label')\n",
    "disp.ax_.get_images()[0].set_clim(0, 1)\n",
    "disp.ax_.get_images()[0].set_cmap('bwr')\n",
    "plt.savefig('plots/conf_matrix.png', dpi = 300, transparent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f45e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now get descriptions\n",
    "results.groupby('human_labeled').median(numeric_only = True).apply(minmax_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c6c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby('sleep').median(numeric_only = True).apply(minmax_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb02972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to excel\n",
    "results.groupby('human_labeled').median(numeric_only = True).apply(minmax_scale).to_excel('results/human_labeled_state_params.xlsx')\n",
    "results.groupby('sleep').median(numeric_only = True).apply(minmax_scale).to_excel('results/clusterer_state_params.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd7b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count\n",
    "results.groupby('human_labeled').count()/len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dbe66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count\n",
    "results.groupby('sleep').count()/len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd937f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to excel\n",
    "(results.groupby('human_labeled').count()/len(results)).to_excel('results/human_labeled_counts.xlsx')\n",
    "(results.groupby('sleep').count()/len(results)).to_excel('results/clusterer_counts.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c962e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get state durations and counts\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676418d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations_human = []\n",
    "for id in results['id'].unique():\n",
    "    duration_analysis = results.loc[results['id']==id].drop(['delta','theta','alpha','beta','gamma', 'emg'], axis = 1)\n",
    "    duration_analysis['sleep_numeric'] = duration_analysis['human_labeled'].replace({'W':0,'N':1, 'R':2}).astype(int)\n",
    "    duration_analysis['diff'] = duration_analysis['sleep_numeric'].diff()\n",
    "    state_switches = duration_analysis.loc[(duration_analysis['diff']!=0)]\n",
    "    state_switches['duration'] = 0\n",
    "    state_switches['duration'].iloc[0:-1] = state_switches.index.to_series().diff().dropna().to_numpy()#already in s from previous analysis\n",
    "    state_switches['id'] = id\n",
    "    durations_human.append(state_switches)\n",
    "durations_human = pd.concat(durations_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bcfdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations_human.groupby('human_labeled').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c338b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations_human.groupby('human_labeled').count()/len(durations_human['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83800685",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations_auto = []\n",
    "for id in results['id'].unique():\n",
    "    duration_analysis = results.loc[results['id']==id].drop(['delta','theta','alpha','beta','gamma', 'emg'], axis = 1)\n",
    "    duration_analysis['sleep_numeric'] = duration_analysis['sleep'].replace({'W':0,'N':1, 'R':2}).astype(int)\n",
    "    duration_analysis['diff'] = duration_analysis['sleep_numeric'].diff()\n",
    "    state_switches = duration_analysis.loc[(duration_analysis['diff']!=0)]\n",
    "    state_switches['duration'] = 0\n",
    "    state_switches['duration'].iloc[0:-1] = state_switches.index.to_series().diff().dropna().to_numpy()#already in s from previous analysis\n",
    "    state_switches['id'] = id\n",
    "    durations_auto.append(state_switches)\n",
    "durations_auto = pd.concat(durations_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86469231",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations_auto.groupby('human_labeled').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1263ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations_auto.groupby('human_labeled').count()/len(durations_human['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad0a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct\n",
    "correct = results.loc[results['sleep']==results['human_labeled']]\n",
    "#sleep params where my classification was incorrect\n",
    "correct.groupby('human_labeled').median(numeric_only=True).apply(minmax_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622cf65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure out where my method makes mistakes\n",
    "mistakes = results.loc[results['sleep']!=results['human_labeled']]\n",
    "#sleep params where my classification was incorrect\n",
    "mistakes.groupby('human_labeled').median(numeric_only=True).apply(minmax_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb61039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot - single rat\n",
    "rats = results['id'].unique()\n",
    "rat = rats[0]\n",
    "single_rat = results[results['id']==rat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0224fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1,figsize=(10,6))\n",
    "time = np.arange(0,len(single_rat))/(15*60)\n",
    "axs[0].plot(time, single_rat['sleep'])\n",
    "axs[0].set(title = 'Rule-based classifier', xlabel = 'Time, hours from start', ylabel = 'Sleep state', xlim = (-0.5,24.5))\n",
    "ymin, ymax = axs[0].get_ylim()\n",
    "axs[0].vlines(time[int(np.floor(len(time)/2))], ymin, ymax, color = 'k', linestyles = '--')\n",
    "axs[0].vlines(time[0], ymin, ymax, color = 'r', linestyles = '--')\n",
    "axs[0].locator_params(axis = 'x', nbins = 24)\n",
    "\n",
    "axs[1].plot(time, single_rat['human_labeled'])\n",
    "axs[1].set(title = 'Human labels', xlabel = 'Time, hours from start', ylabel = 'Sleep state', xlim = (-0.5,24.5))\n",
    "ymin, ymax = axs[1].get_ylim()\n",
    "axs[1].vlines(time[int(np.floor(len(time)/2))], ymin, ymax, color = 'k', linestyles = '--')\n",
    "axs[1].vlines(time[0], ymin, ymax, color = 'r', linestyles = '--')\n",
    "axs[1].locator_params(axis = 'x', nbins = 24)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/classifiervshuman.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fa5d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cat = CategoricalDtype(categories = ['Yes','No'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a876f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now check where mistakes happens\n",
    "fig, axs = plt.subplots(3,1,figsize=(10,8))\n",
    "time = np.arange(0,len(single_rat))/(15*60)\n",
    "axs[0].plot(time, single_rat['sleep'])\n",
    "axs[0].set(title = 'Rule-based classifier', xlabel = 'Time, hours from start', ylabel = 'Sleep state', xlim = (-0.5,24.5))\n",
    "ymin, ymax = axs[0].get_ylim()\n",
    "axs[0].vlines(time[int(np.floor(len(time)/2))], ymin, ymax, color = 'k', linestyles = '--')\n",
    "axs[0].vlines(time[0], ymin, ymax, color = 'r', linestyles = '--')\n",
    "axs[0].locator_params(axis = 'x', nbins = 24)\n",
    "\n",
    "axs[1].plot(time, single_rat['human_labeled'])\n",
    "axs[1].set(title = 'Human labels', xlabel = 'Time, hours from start', ylabel = 'Sleep state', xlim = (-0.5,24.5))\n",
    "ymin, ymax = axs[1].get_ylim()\n",
    "axs[1].vlines(time[int(np.floor(len(time)/2))], ymin, ymax, color = 'k', linestyles = '--')\n",
    "axs[1].vlines(time[0], ymin, ymax, color = 'r', linestyles = '--')\n",
    "axs[1].locator_params(axis = 'x', nbins = 24)\n",
    "\n",
    "axs[2].plot(time, (single_rat['human_labeled']==single_rat['sleep']).replace({True:'Yes',False:'No'}).astype(bool_cat))\n",
    "axs[2].set(title = 'Human labels', xlabel = 'Time, hours from start', ylabel = 'Do labels match?', xlim = (-0.5,24.5))\n",
    "ymin, ymax = axs[2].get_ylim()\n",
    "axs[2].vlines(time[int(np.floor(len(time)/2))], ymin, ymax, color = 'k', linestyles = '--')\n",
    "axs[2].vlines(time[0], ymin, ymax, color = 'r', linestyles = '--')\n",
    "axs[2].locator_params(axis = 'x', nbins = 24)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/classifiervshumanwithdiff.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c3c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now check where mistakes happens\n",
    "single_hour = single_rat.iloc[2000:3000]\n",
    "fig, axs = plt.subplots(3,1,figsize=(10,8))\n",
    "time = np.arange(0,len(single_hour))/(15)\n",
    "axs[0].plot(time, single_hour['sleep'])\n",
    "axs[0].set(title = 'Rule-based classifier', xlabel = 'Time, minutes', ylabel = 'Sleep state')#, xlim = (-0.5,24.5))\n",
    "axs[0].locator_params(axis = 'x', nbins = 24)\n",
    "\n",
    "axs[1].plot(time, single_hour['human_labeled'])\n",
    "axs[1].set(title = 'Human labels', xlabel = 'Time, minutes', ylabel = 'Sleep state')#, xlim = (-0.5,24.5))\n",
    "axs[1].locator_params(axis = 'x', nbins = 24)\n",
    "\n",
    "axs[2].plot(time, (single_hour['human_labeled']==single_hour['sleep']).replace({True:'Yes',False:'No'}).astype(bool_cat))\n",
    "axs[2].set(title = 'Human labels', xlabel = 'Time, minutes', ylabel = 'Do labels match?')#, xlim = (-0.5,24.5))\n",
    "axs[2].locator_params(axis = 'x', nbins = 24)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/classifiervshumanwithdiffsinglehour.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basicdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "1632b40a422678b2501f8c20c187304741cc7354487dfb6e2a6c80ec080d17a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
